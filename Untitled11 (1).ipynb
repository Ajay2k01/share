{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "g21uVGhUcX3R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,IsolationForest\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class pred_analysis:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def details(self,df,target):                         #No return\n",
        "    print(\"shape=\",df.shape)\n",
        "    print(\"\\n\")\n",
        "    print(\"duplicates=\")\n",
        "    print(df[df.duplicated()].count())\n",
        "    print(\"\\n\")\n",
        "    print(\"Nulls=\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\n\")\n",
        "    print(\"balance=\")\n",
        "    print(df[target].value_counts())\n",
        "\n",
        "  def balance(self,df,target):\n",
        "    df1=df[df[target]==0]\n",
        "    df2=df[df[target]==1]\n",
        "    mini=min(df[target].value_counts().values)\n",
        "    maxi=max(df[target].value_counts().values)\n",
        "    if len(df1)>len(df2):\n",
        "      df1_new=resample(df1,random_state=42,replace=True,n_samples=mini)\n",
        "      df=pd.concat([df1_new,df2])\n",
        "    else:\n",
        "      df2_new=resample(df2,random_state=42,replace=True,n_samples=mini)\n",
        "      df=pd.concat([df1,df2_new])\n",
        "    return df\n",
        "\n",
        "  def preprocess(self,df,target):\n",
        "    if \"Unnamed: 0\" in df.columns:\n",
        "      df=df.drop(\"Unnamed: 0\",axis=1)\n",
        "    df.fillna(method=\"ffill\",inplace=True)\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "  def check_outliers(self,df):\n",
        "    num_col=df.columns[df.dtypes!=object]\n",
        "    for i in num_col:\n",
        "      sns.boxplot(df[i])\n",
        "      plt.title(i)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def remove_outliers(self,df):\n",
        "    num_col=df.columns[df.dtypes!=object]\n",
        "    for i in num_col:\n",
        "      q1=df[i].quantile(0.25)\n",
        "      q3=df[i].quantile(0.75)\n",
        "\n",
        "      iqr=q3-q1\n",
        "      med=df[i].median()\n",
        "      df[i]=np.where((df[i]<q1-(1.5*iqr)) | (df[i]>q3+(1.5*iqr)),med,df[i])\n",
        "    return df\n",
        "\n",
        "  def encoder(self,df,lst):                                 #  No return\n",
        "    for i in lst:\n",
        "      df[i]=preprocessing.LabelEncoder().fit_transform(df[i])\n",
        "\n",
        "  def data_split(self,df,target,size):\n",
        "    X=df.drop(columns=[target])\n",
        "    y=df[target]\n",
        "    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=size,random_state=42)\n",
        "    print(f'Records in dataset: {df.shape[0]}')\n",
        "    print(f'Records in train dataset: {x_train.shape[0]}')\n",
        "    print(f'Records in test dataset: {x_test.shape[0]}')\n",
        "    return (x_train,x_test,y_train,y_test)\n",
        "\n",
        "  def metrics(self,y_test,res):\n",
        "    print(f\"Accuracy score={accuracy_score(y_test,res)*100}\")\n",
        "    print(f\"precision={precision_score(y_test,res)}\")\n",
        "    print(f\"Recall={recall_score(y_test,res)*100}\")\n",
        "    print(f\"F1 score={f1_score(y_test,res)*100}\")\n",
        "    print(f\"Confusion Matrix=\")\n",
        "    conf_matrix=confusion_matrix(y_test,res)\n",
        "    sns.heatmap(conf_matrix,annot=True)\n",
        "    plt.show()\n",
        "\n",
        "  def model_execute(self,models,tup):\n",
        "    x_train,x_test,y_train,y_test=tup\n",
        "    for mod in models:\n",
        "      clf=models[mod]\n",
        "      clf.fit(x_train,y_train)\n",
        "      res=clf.predict(x_test)\n",
        "      print(f\"{clf}\")\n",
        "      print(\"\\n\")\n",
        "      self.metrics(y_test,res)"
      ],
      "metadata": {
        "id": "xacpfjSSgejw"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec=DecisionTreeClassifier()\n",
        "models={\"Logreg\":LogisticRegression(),\"Rf\":RandomForestClassifier(),\"dt\":dec,\"knn\":KNeighborsClassifier(),\"Naive Bayes\": GaussianNB(),\n",
        "        \"ada\":AdaBoostClassifier(base_estimator=dec,n_estimators=50,random_state=42),\"xgb\":XGBClassifier()}"
      ],
      "metadata": {
        "id": "wzoDtC7ipI1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}